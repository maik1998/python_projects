{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michael Mendoza Lozano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# carga de dataset\n",
    "digitos = datasets.load_digits()\n",
    "\n",
    "X = digitos['data']\n",
    "t = digitos['target']\n",
    "\n",
    "print(X)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Desarrolle una función que simule el $holdout$ $method$. El porcentaje de $X$ que se va a usar para entrenar debe estar parametrizado. No debe usar niguna dependecia a parte de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdoutMethod(trainSize):\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(t)\n",
    "    testSize=1-trainSize\n",
    "    splitEX=int(trainSize*len(X))\n",
    "    splitPX=int(testSize*len(X))\n",
    "    splitEt=int(trainSize*len(t))\n",
    "    splitPt=int(testSize*len(t))\n",
    "    \n",
    "    X_train = X[:splitEX]\n",
    "    t_train = t[:splitEt]\n",
    "    X_test =  X[:splitPX]\n",
    "    t_test = t[:splitPt]\n",
    "    \n",
    "    return X_train,X_test, t_train, t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Usando la función desarrollada en el punto 2, divida los datos con el 70% para entrenar y el 30% para prueba. Use la dependencia de RNA para clasificar, entrenar y predecir usando tanto el conjunto de entrenamiento como el de pruebas. Use como solver sgd y como función de activación la función logística.\n",
    "Usando accuracy_score determine la exactitud para t de entrenamiento y t de pruebas <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">Ver</a>.\n",
    "\n",
    "¿Qué resultados obtuvo, intérprete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.994431185361973\n"
     ]
    }
   ],
   "source": [
    "train_size=0.70\n",
    "X_train, X_test, t_train, t_test=holdoutMethod(train_size)\n",
    "\n",
    "clfx=MLPClassifier(activation = 'logistic', solver = 'sgd', max_iter = 7500).fit(X_train,t_train)\n",
    "clft=MLPClassifier(activation = 'logistic', solver = 'sgd', max_iter = 7500).fit(X_test,t_test)\n",
    "tPpredic=clfx.predict(X_train)\n",
    "tpredic=clft.predict(X_test)\n",
    "print(accuracy_score(t_test,tpredic))\n",
    "print(accuracy_score(t_train,tPpredic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo una exactitud del 100% para el t de pruebas y un 99% para el t de entrenamiento, lo cual nos deja ver que la función de activación logistica se adapta mejor, aunque se demora en converger por esta razon el numero de iteracciones se amplia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Siga los siguientes pasos:\n",
    "* Use Normalizer para normalizar el conjunto de entrenamiento <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\">Ver</a>.\n",
    "* Use train_test_split para armar el conjunto de entrenamiento y el conjunto de pruebas. Use 70% para entrenar y 30% para pruebas <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#\">Ver</a>.\n",
    "* Use una red neuronal con los parámetros que desee, para generar un buen modelo <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">Ver</a>.\n",
    "* Prediga los resultados para t de entrenamiento y t de pruebas. Usando accuracy_score determine la exactitud para t de entrenamiento y t de pruebas <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">Ver</a>. \n",
    "* ¿Qué resultados obtuvo? Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "XN = Normalizer().fit(X)\n",
    "XN =XN.transform(X)\n",
    "X_train1, X_test1, t_train1, t_test1= train_test_split(XN,t,train_size=0.7)\n",
    "\n",
    "clf=MLPClassifier(activation = 'tanh', solver = 'lbfgs', max_iter = 2000).fit(X_train1,t_train1)\n",
    "clf2=MLPClassifier(activation = 'tanh', solver = 'lbfgs', max_iter = 2000).fit(X_test1,t_test1)\n",
    "tP1predic1=clf2.predict(X_test1)\n",
    "tpredic1=clf.predict(X_train1)\n",
    "print((accuracy_score(t_test1,tP1predic1)))\n",
    "print((accuracy_score(t_train1,tpredic1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo una exactitud del 100 % para el t de pruebas y un 100% para el t de entrenamiento, ademas de esto se escogio la función de activación tan hiperbólica y el solver lbfgs que nos ayuda a converger un poco mas rapido y si comparamos con el punto 2 las iteracciones necesarias para que converga son menores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Ahora usando cross_val_score con un cv = 7 (<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\">Ver</a>), ajuste un buen modelo ¿Qué resultados obtuvo? Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11597923 0.08328835 0.08580369 0.11591377 0.08321929 0.0917124\n",
      " 0.12544491]\n",
      "0.10 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf,XN,t, cv=7, scoring='f1_macro')\n",
    "print(scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
